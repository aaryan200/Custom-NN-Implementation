{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9995,  0.1025],\n",
      "         [-0.4816,  1.2860]],\n",
      "\n",
      "        [[-0.1652,  0.4024],\n",
      "         [ 0.1378, -1.2458]],\n",
      "\n",
      "        [[ 1.8742, -0.9989],\n",
      "         [-0.8966, -0.8257]],\n",
      "\n",
      "        [[ 0.2927,  0.7121],\n",
      "         [ 1.3994, -1.1206]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.randn(4, 2, 2)\n",
    "print(tensor)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = torch.nn.Dropout(0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000],\n",
      "         [-0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.4129,  0.0000],\n",
      "         [ 0.3444, -0.0000]],\n",
      "\n",
      "        [[ 4.6855, -2.4972],\n",
      "         [-0.0000, -0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000],\n",
      "         [ 0.0000, -2.8015]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op = dropout(tensor)\n",
    "print(op)\n",
    "op.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `view` and `transpose` operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.1589,  0.5802,  0.4998, -1.3935],\n",
      "         [ 1.1295, -0.1280,  0.4573,  1.2726],\n",
      "         [ 0.4439, -0.8118,  1.8655, -0.1175],\n",
      "         [ 0.8269,  1.5722, -0.0410,  0.5759]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.1589,  0.5802],\n",
       "          [ 0.4998, -1.3935]],\n",
       "\n",
       "         [[ 1.1295, -0.1280],\n",
       "          [ 0.4573,  1.2726]],\n",
       "\n",
       "         [[ 0.4439, -0.8118],\n",
       "          [ 1.8655, -0.1175]],\n",
       "\n",
       "         [[ 0.8269,  1.5722],\n",
       "          [-0.0410,  0.5759]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.randn(1, 4, 4)\n",
    "print(tensor)\n",
    "tensor = tensor.view(1, 4, 2, 2)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.1589,  0.5802],\n",
      "          [ 1.1295, -0.1280],\n",
      "          [ 0.4439, -0.8118],\n",
      "          [ 0.8269,  1.5722]],\n",
      "\n",
      "         [[ 0.4998, -1.3935],\n",
      "          [ 0.4573,  1.2726],\n",
      "          [ 1.8655, -0.1175],\n",
      "          [-0.0410,  0.5759]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 4, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_tr = tensor.transpose(1, 2)\n",
    "print(tensor_tr)\n",
    "tensor_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "transpose(input, dim0, dim1) -> Tensor\n",
      "\n",
      "Returns a tensor that is a transposed version of :attr:`input`.\n",
      "The given dimensions :attr:`dim0` and :attr:`dim1` are swapped.\n",
      "\n",
      "If :attr:`input` is a strided tensor then the resulting :attr:`out`\n",
      "tensor shares its underlying storage with the :attr:`input` tensor, so\n",
      "changing the content of one would change the content of the other.\n",
      "\n",
      "If :attr:`input` is a :ref:`sparse tensor <sparse-docs>` then the\n",
      "resulting :attr:`out` tensor *does not* share the underlying storage\n",
      "with the :attr:`input` tensor.\n",
      "\n",
      "If :attr:`input` is a :ref:`sparse tensor <sparse-docs>` with compressed\n",
      "layout (SparseCSR, SparseBSR, SparseCSC or SparseBSC) the arguments\n",
      ":attr:`dim0` and :attr:`dim1` must be both batch dimensions, or must\n",
      "both be sparse dimensions. The batch dimensions of a sparse tensor are the\n",
      "dimensions preceding the sparse dimensions.\n",
      "\n",
      ".. note::\n",
      "    Transpositions which interchange the sparse dimensions of a `SparseCSR`\n",
      "    or `SparseCSC` layout tensor will result in the layout changing between\n",
      "    the two options. Transposition of the sparse dimensions of a ` SparseBSR`\n",
      "    or `SparseBSC` layout tensor will likewise generate a result with the\n",
      "    opposite layout.\n",
      "\n",
      "\n",
      "Args:\n",
      "    input (Tensor): the input tensor.\n",
      "    dim0 (int): the first dimension to be transposed\n",
      "    dim1 (int): the second dimension to be transposed\n",
      "\n",
      "Example::\n",
      "\n",
      "    >>> x = torch.randn(2, 3)\n",
      "    >>> x\n",
      "    tensor([[ 1.0028, -0.9893,  0.5809],\n",
      "            [-0.1669,  0.7299,  0.4942]])\n",
      "    >>> torch.transpose(x, 0, 1)\n",
      "    tensor([[ 1.0028, -0.1669],\n",
      "            [-0.9893,  0.7299],\n",
      "            [ 0.5809,  0.4942]])\n",
      "\n",
      "See also :func:`torch.t`.\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "torch.transpose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 2)\n",
      "[[[1, 2], [5, 6]], [[3, 4], [7, 8]]]\n"
     ]
    }
   ],
   "source": [
    "def transpose_any_dims(tensor, dim0, dim1):\n",
    "    # Create a list of the dimensions in their original order\n",
    "    dims = list(range(len(tensor)))\n",
    "\n",
    "    # Swap the two dimensions\n",
    "    dims[dim0], dims[dim1] = dims[dim1], dims[dim0]\n",
    "\n",
    "    # Create a recursive function to transpose the tensor\n",
    "    def transpose_recursive(tensor, dims):\n",
    "        if len(dims) == 1:\n",
    "            return tensor\n",
    "        else:\n",
    "            return [transpose_recursive(list(t), dims[1:]) for t in zip(*tensor)]\n",
    "\n",
    "    # Use the recursive function with the new order of dimensions\n",
    "    return transpose_recursive(tensor, dims)\n",
    "\n",
    "# Example usage:\n",
    "tensor_ex = [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]  # A 3D tensor\n",
    "print(np.array(tensor_ex).shape)\n",
    "print(transpose_any_dims(tensor_ex, 0, 1))  # Transpose dimensions 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `nn.Parameter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.nn.Parameter(torch.randn(1, 1))\n",
    "isinstance(a, torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "contiguous(memory_format=torch.contiguous_format) -> Tensor\n",
      "\n",
      "Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If\n",
      ":attr:`self` tensor is already in the specified memory format, this function returns the\n",
      ":attr:`self` tensor.\n",
      "\n",
      "Args:\n",
      "    memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "        returned Tensor. Default: ``torch.contiguous_format``.\n",
      "\u001b[0;31mType:\u001b[0m      method_descriptor"
     ]
    }
   ],
   "source": [
    "torch.Tensor.contiguous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaryan/penvs/nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('cfilt/iitb-english-hindi', split = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['translation'],\n",
       "    num_rows: 1659083\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28800.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32_000 * 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 100 samples from the dataset\n",
    "data = data.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'translation': {'en': 'Give your application an accessibility workout', 'hi': 'अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें'}}\n"
     ]
    }
   ],
   "source": [
    "# Print one sample from the train dataset\n",
    "sample = data[0]\n",
    "print(type(sample))\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import  random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43, 74, 61, 95, 72, 11, 88, 47, 82, 63, 35, 81, 6, 44, 42, 48, 16, 73, 26, 14, 18, 69, 83, 70, 89, 45, 10, 25, 1, 19, 68, 52, 38, 12, 80, 59, 21, 56, 64, 76, 97, 53, 57, 55, 49, 96, 5, 90, 13, 4, 65, 37, 71, 46, 51, 87, 75, 66, 39, 22, 3, 79, 30, 2, 86, 85, 17, 33, 62, 34, 50, 7, 67, 94, 9, 40, 24, 41, 99, 91, 36, 58, 27, 98, 77, 28, 60, 84, 31, 29]\n",
      "[54, 92, 0, 23, 32, 15, 93, 8, 78, 20]\n"
     ]
    }
   ],
   "source": [
    "splits = random_split(data, [90, 10])\n",
    "for split in splits:\n",
    "    print(split.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `torch.triu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1309, -0.1964, -1.0162],\n",
       "        [ 0.7027, -0.0395, -1.3087],\n",
       "        [-0.6452, -1.2540,  0.3653]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1309, -0.1964, -1.0162],\n",
       "        [ 0.0000, -0.0395, -1.3087],\n",
       "        [ 0.0000,  0.0000,  0.3653]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.1964, -1.0162],\n",
       "        [ 0.0000,  0.0000, -1.3087],\n",
       "        [ 0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(a, diagonal=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huggingface `WordLevel` tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tokenizers.Tokenizer at 0x7f3ed64fe230>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(WordLevel(unk_token='[UNK]'))\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer = Whitespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = WordLevelTrainer(special_tokens = [\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"],\n",
    "                                   min_frequency = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [\"This is a test\", \"This is another test\", \"This is a test\",\n",
    "      \"Hello world\", \"Hello world\", \"Hello world\", \"Hello world\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([word for sent in ds for word in sent.split(' ')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sentences(ds):\n",
    "    for item in ds:\n",
    "        yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.train_from_iterator(get_all_sentences(ds), trainer = trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is another test\n",
      "[6, 7, 0, 8]\n",
      "['This', 'is', '[UNK]', 'test']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize a sentence using the tokenizer\n",
    "# \"another\" should not be in the vocabulary, because it appears only once\n",
    "s = \"This is another test\"\n",
    "print(s)\n",
    "output = tokenizer.encode(s)\n",
    "print(output.ids)\n",
    "print(output.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.token_to_id(\"[UNK]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3, 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "squeeze(input, dim=None) -> Tensor\n",
      "\n",
      "Returns a tensor with all specified dimensions of :attr:`input` of size `1` removed.\n",
      "\n",
      "For example, if `input` is of shape:\n",
      ":math:`(A \\times 1 \\times B \\times C \\times 1 \\times D)` then the `input.squeeze()`\n",
      "will be of shape: :math:`(A \\times B \\times C \\times D)`.\n",
      "\n",
      "When :attr:`dim` is given, a squeeze operation is done only in the given\n",
      "dimension(s). If `input` is of shape: :math:`(A \\times 1 \\times B)`,\n",
      "``squeeze(input, 0)`` leaves the tensor unchanged, but ``squeeze(input, 1)``\n",
      "will squeeze the tensor to the shape :math:`(A \\times B)`.\n",
      "\n",
      ".. note:: The returned tensor shares the storage with the input tensor,\n",
      "          so changing the contents of one will change the contents of the other.\n",
      "\n",
      ".. warning:: If the tensor has a batch dimension of size 1, then `squeeze(input)`\n",
      "          will also remove the batch dimension, which can lead to unexpected\n",
      "          errors. Consider specifying only the dims you wish to be squeezed.\n",
      "\n",
      "Args:\n",
      "    input (Tensor): the input tensor.\n",
      "    dim (int or tuple of ints, optional): if given, the input will be squeezed\n",
      "           only in the specified dimensions.\n",
      "\n",
      "        .. versionchanged:: 2.0\n",
      "           :attr:`dim` now accepts tuples of dimensions.\n",
      "\n",
      "Example::\n",
      "\n",
      "    >>> x = torch.zeros(2, 1, 2, 1, 2)\n",
      "    >>> x.size()\n",
      "    torch.Size([2, 1, 2, 1, 2])\n",
      "    >>> y = torch.squeeze(x)\n",
      "    >>> y.size()\n",
      "    torch.Size([2, 2, 2])\n",
      "    >>> y = torch.squeeze(x, 0)\n",
      "    >>> y.size()\n",
      "    torch.Size([2, 1, 2, 1, 2])\n",
      "    >>> y = torch.squeeze(x, 1)\n",
      "    >>> y.size()\n",
      "    torch.Size([2, 2, 1, 2])\n",
      "    >>> y = torch.squeeze(x, (1, 2, 3))\n",
      "    torch.Size([2, 2, 2])\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "torch.squeeze?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 6, 7, 0, 8, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_ids = tokenizer.encode(s).ids\n",
    "pad_token = torch.tensor([tokenizer.token_to_id(\"[PAD]\")], dtype = torch.int64)\n",
    "sos_token = torch.tensor([tokenizer.token_to_id(\"[SOS]\")], dtype = torch.int64)\n",
    "eos_token = torch.tensor([tokenizer.token_to_id(\"[EOS]\")], dtype = torch.int64)\n",
    "# print(pad_token)\n",
    "\n",
    "enc_input = torch.cat([\n",
    "    sos_token,\n",
    "    torch.tensor(op_ids, dtype = torch.int64),\n",
    "    eos_token,\n",
    "    torch.tensor([pad_token] * 10, dtype = torch.int64).squeeze()\n",
    "], dim = 0)\n",
    "\n",
    "enc_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(enc_input != pad_token).unsqueeze(0).unsqueeze(0).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "unsqueeze(input, dim) -> Tensor\n",
      "\n",
      "Returns a new tensor with a dimension of size one inserted at the\n",
      "specified position.\n",
      "\n",
      "The returned tensor shares the same underlying data with this tensor.\n",
      "\n",
      "A :attr:`dim` value within the range ``[-input.dim() - 1, input.dim() + 1)``\n",
      "can be used. Negative :attr:`dim` will correspond to :meth:`unsqueeze`\n",
      "applied at :attr:`dim` = ``dim + input.dim() + 1``.\n",
      "\n",
      "Args:\n",
      "    input (Tensor): the input tensor.\n",
      "    dim (int): the index at which to insert the singleton dimension\n",
      "\n",
      "Example::\n",
      "\n",
      "    >>> x = torch.tensor([1, 2, 3, 4])\n",
      "    >>> torch.unsqueeze(x, 0)\n",
      "    tensor([[ 1,  2,  3,  4]])\n",
      "    >>> torch.unsqueeze(x, 1)\n",
      "    tensor([[ 1],\n",
      "            [ 2],\n",
      "            [ 3],\n",
      "            [ 4]])\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "torch.unsqueeze?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello/1.pt'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(Path('.') / \"hello\" / \"1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100\n",
      "Processing 101\n",
      "Processing 102\n",
      "Processing 103\n",
      "Processing 104\n"
     ]
    }
   ],
   "source": [
    "for i in range(100, 105):\n",
    "    print(f'Processing {i:02d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am  0.100'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = 0.1\n",
    "f'I am {sm:6.3f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
